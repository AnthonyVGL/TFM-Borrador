# -*- coding: utf-8 -*-
"""14MBID_TFM_Anthony_Valerio_Gomez_Lizana.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xWqpZ7eCsGnLg08AgmYdv60cufGGY2jk

# <center>T-068 Control de Calidad Agroalimentario: Análisis Predictivo en Uvas a Diferentes Puntos de Madurez

**Nombre y apellidos:** Anthony Valerio Gomez Lizana

**Usuario VIU:** anthonyvalerio.gomez (anthonyvalerio.gomez@student.universidadviu.com)

---
# Resumen
---

El proyecto busca desarrollar un modelo predictivo que utilice espectroscopía para monitorear la calidad de las uvas, utilizando la espectroscopía de infrarrojo medio (MIR).
El objetivo es correlacionar los datos espectroscópicos con parámetros de calidad clave como la dulzura y acidez, identificando patrones que correspondan a diferentes estados de madurez y su evolución en el tiempo. Se pretende proporcionar una metodología rápida, no destructiva y eficiente para el control de calidad, facilitando decisiones informadas en la cadena de producción vitivinícola.

---
# Exploración
---

Importamos las bibliotecas a utilizar
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from mpl_toolkits.mplot3d import Axes3D
from scipy.cluster import hierarchy
from scipy.signal import savgol_filter
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.model_selection import cross_val_score

"""Subimos los archivos csv de los datos del espectrómetro y calidad y guardamos respectivamente por con los nombres matriz_x y matriz_y"""

# Lee los archivos CSV
matriz_x = pd.read_csv('/content/MatrizX_Uva.csv')  # Datos del espectrómetro
matriz_y = pd.read_csv('/content/MatrizY_Uva.csv', delimiter=';')  # Valores de Brix y pH

"""Mostramos el contenido del archivo matriz_y"""

print(matriz_y.shape)
matriz_y.head()

""" Modificamos el nombre de la primera columna para un manejo adecuado"""

matriz_y = matriz_y.rename(columns={"º Brix": "Brix"})
print(matriz_y.shape)
matriz_y.head()

"""Mostramos el archivo matriz_x"""

print(matriz_x.shape)
matriz_x.head(15)

"""El dataset matriz_x necesita darle forma para una estructura adecuada, para ello se eliminará las filas con información innecesaria y se adaptará de la siguiente forma"""

# Elimina las primeras 6 filas
matriz_x = matriz_x.drop(matriz_x.index[:6])

# Se llena los valores de la primera fila con los de la segunda donde sean NaN
matriz_x.iloc[0] = matriz_x.iloc[0].combine_first(matriz_x.iloc[1])

# Se elimina la fila con indice 1
matriz_x = matriz_x.drop(matriz_x.index[1])
matriz_x = matriz_x.drop(matriz_x.index[1])

# Elimina la primera columna
matriz_x = matriz_x.drop(matriz_x.columns[0], axis=1)

# Elimina la última columna
matriz_x = matriz_x.drop(matriz_x.columns[-1], axis=1)

# Restablece la fila 7 (índice 0) como los títulos de las columnas
matriz_x.columns = matriz_x.iloc[0]

# Resetea los índices para evitar saltos en la numeración
matriz_x = matriz_x.reset_index(drop=True)

# Elimina la fila duplicada en el indice 0
matriz_x = matriz_x.drop(matriz_x.index[0])

# Verifica el resultado
matriz_x.head()

"""Teniendo la estructura adecuada observamos que entre las variables esta el analysis date, en el cual se modificará el formato para obtener dos columnas extras una de fecha y otra que contabilizará el número de horas"""

# Función para agregar el 0 faltante al año
def corregir_fecha(fecha):
    if fecha.startswith('021'):
        fecha = '2021' + fecha[3:]
    return fecha

# Aplicar la corrección a la columna 'analysis date'
matriz_x['analysis date corregido'] = matriz_x['analysis date'].apply(corregir_fecha)

# Ahora convertimos la columna corregida a datetime
matriz_x['analysis date corregido'] = pd.to_datetime(matriz_x['analysis date corregido'], format='%Y-%m-%dT%H-%M-%S')

# Finalmente, convertimos el formato al deseado dd/mm/yyyy
matriz_x['Fecha'] = matriz_x['analysis date corregido'].dt.strftime('%d/%m/%Y')

# Se elimina la columna 'analysis date corregido'
matriz_x = matriz_x.drop(columns=["analysis date corregido"])

# Eliminar la columna "sample name"
columna_fecha = matriz_x.pop("sample name")

# Eliminar la columna "Time Index"
columna_fecha = matriz_x.pop("Time Index")

# Eliminar la columna "Replicate"
columna_fecha = matriz_x.pop("Replicate")

# Eliminar la columna "Fecha" y guardarla temporalmente
columna_fecha = matriz_x.pop("Fecha")

# Movemos la columna allado de 'analysis date'
matriz_x.insert(2, "Fecha", columna_fecha)

# Asegurarnos de que la columna 'fecha' está en formato datetime
matriz_x['Fecha'] = pd.to_datetime(matriz_x['Fecha'], format='%d/%m/%Y')

# Agrupar por 'Sample' y restar la fecha mínima de cada grupo para obtener las horas transcurridas
matriz_x['Horas'] = matriz_x.groupby('Sample')['Fecha'].transform(lambda x: (x - x.min()).dt.total_seconds() / 3600)

# Insertar la columna "Horas" en la posición 3
matriz_x.insert(3, "Horas", matriz_x.pop("Horas"))

# Mostrar las primeras filas para verificar
matriz_x.head()

"""Ahora eliminamos las columnas que no aportarán valor como el analysis date y Subfile Index"""

# Eliminar las columnas 'analysis date' y 'Subfile Index'
matriz_x = matriz_x.drop(columns=['analysis date', 'Subfile Index'])

# Verificar que las columnas se hayan eliminado correctamente
matriz_x.head()

"""Ahora el dataset matriz_x contiene las variables adecuadas y una estructura adecuada para el análisis, además de estar compuesta por las siguientes variables:
*   Full name = Codificación al unir Sample, Samplin time, Replicate y analysis date
*   Fecha = Fecha formato "Día/Mes/Año"
*   Horas = La cantidad de Horas de cada Sample desde la primera toma de muestras
*   Sampling time = Es la codificación del momento del tiempo donde se tomó la muestra según el día como la variable fecha_formateada siendo 5 momentos distintos.
*   Sample = Es la muestra tomada del tipo de fermentación siendo la primera o segunda muestra con dichas características.
*   type of fermentation = Tipo de fermentación con las siguientes nomenclaturas:

  M = Variedad, A=Arriba, M=Medio y B=Bajo.

  La primera letra solo tiene el significado de Variedad (M).

  La segunda letra indica la posición de la Viña en donde se tiene la medida de la uva sea A, M o B.

  La tercera letra indica la posición de racismo de uva dentro de la planta sea A, M o B.

A partir de la columna Sample se muestra los distintos números de onda (cm-1)

Identificación de valores nulos o faltantes de cada matriz
"""

# Para matriz_x
nulos_x = matriz_x.isnull().sum()
print("Valores nulos en matriz_x:")
print(nulos_x[nulos_x > 0])

# Para matriz_y
if isinstance(matriz_y, pd.DataFrame):
    nulos_y = matriz_y.isnull().sum()
    print("Valores nulos en matriz_y:")
    print(nulos_y[nulos_y > 0])

"""Se observa en el resultado es 0 en cada matriz por lo que los datasets tienen completa su información

Ahora graficaremos las muestras en todos los espectros
"""

espectros = matriz_x.iloc[:, 7:]  # Todas las filas y columnas a partir de la 7
numeros_onda = matriz_x.columns[7:]  # Los nombres de las columnas de números de onda

# Graficamos los espectros de todas las filas
plt.figure(figsize=(12, 8))

# Iteramos sobre todas las filas
for i in range(espectros.shape[0]):
    plt.plot(numeros_onda, espectros.iloc[i, :], label=f'Fila {i+1}')  # Graficamos cada fila

# Configuramos el gráfico
plt.title('Espectros de todas las filas de matriz_x')
plt.xlabel('Números de onda (cm-1)')
plt.ylabel('Intensidad')
plt.grid(True)
plt.tight_layout()
plt.show()

"""Se observa que la diferencia más notoría se centra entre los números de onda entre (900, 1500) y (3200, 3400), se realizará el gráfico en ese rango."""

# Filtramos los números de onda entre 900 y 1500 cm-1
rango_espectros = (numeros_onda >= 900) & (numeros_onda <= 1500)
espectros_filtrados = espectros.loc[:, rango_espectros]
numeros_onda_filtrados = numeros_onda[rango_espectros]  # Números de onda filtrados

# Graficamos los espectros de todas las filas
plt.figure(figsize=(12, 8))

# Iteramos sobre todas las filas
for i in range(espectros_filtrados.shape[0]):
    plt.plot(numeros_onda_filtrados, espectros_filtrados.iloc[i, :], label=f'Fila {i+1}')  # Graficamos cada fila

# Configuramos el gráfico
plt.title('Espectros de todas las filas de matriz_x (900-1500 cm-1)')
plt.xlabel('Números de onda (cm-1)')
plt.ylabel('Intensidad')
plt.grid(True)
plt.tight_layout()
plt.show()

"""Todas las muestran siguen el mismo patrón, casi ni parece cruzarse entre sí, es un indicio de que en estos niveles de números de onda captan mayor la variabilidad de las muestras entre sí.

Ahora se graficará un mapa de calor considerando solo las variables de Horas y type of fermentation en relación al Brix y pH
"""

# Preparar los datos (Horas, tipo de fermentación, Brix y pH)
X_completo = matriz_x[['Horas', 'type of fermentation']].copy()

# Codificar la variable 'type of fermentation'
X_completo = pd.get_dummies(X_completo, columns=['type of fermentation'], drop_first=False)

# Agregar las variables objetivo (Brix y pH) desde matriz_y
X_completo['Brix'] = matriz_y['Brix']
X_completo['pH'] = matriz_y['pH']

# Calcular la matriz de correlación
correlacion = X_completo.corr()

# Visualizar el mapa de calor
plt.figure(figsize=(8, 6))
sns.heatmap(correlacion, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Mapa de calor de correlaciones entre Horas, Tipo de fermentación, Brix y pH')
plt.show()

"""Se observa que las Horas tienen una relación no muy fuerte con el Brix pero de manera significante a comparación entre el tipo de fermentación.

El pH tiene una relación negativa bastante consecuente pero débil con la posición del racismo de la uva, ya que todas las combinaciones MAB, MBB y MMB terminan en B (posición Bajo).

La relación más fuerte la tienen el Brix y el pH siendo estas valores de Matriz_y

---
# Tratamiento
---

Se plantea usar todos los datos posibles que tengan algún tipo de relación con los valores a predecir Brix y pH.

Para el tratamiento de preparar los datos se usarán todas las variables de espectros y se considerará las variables Horas y Tipo de fermentación (type of fermentation).
"""

# Preparar los datos
X_completo = pd.concat([espectros, matriz_x[['Horas', 'type of fermentation']]], axis=1)

# Codificación de variables categóricas ('type of fermentation')
X_completo = pd.get_dummies(X_completo, columns=['type of fermentation'], drop_first=False)

# Normalizar solo la columna 'Horas'
scaler = StandardScaler()

# Normalizamos solo la columna 'Horas'
X_completo[['Horas']] = scaler.fit_transform(X_completo[['Horas']])
X_completo.columns = X_completo.columns.astype(str)
X_completo.head()

"""Al aplicar pd.get_dummies() para convertir la columna type of fermentation en variables dummy, la columna original type of fermentation se convierte en varias columnas binarias, cada una representando una categoría diferente del tipo de fermentación para poder procesarlas en el modelo.

Se realiza la separación de los datos para el entrenamiento y el test en un 70% y 30% ya que es el que mejor resultados da.
"""

# Separar en conjunto de entrenamiento para Brix
y_brix = matriz_y.iloc[:, 0].values  # Seleccionar solo la columna de Brix
y_ph = matriz_y.iloc[:, 1].values  # Seleccionar solo la columna de pH

# Usar train_test_split para dividir los datos aleatoriamente
X_train, X_test, y_train, y_test = train_test_split(X_completo, y_brix, test_size=0.3, random_state=42)

"""----
#Predicción Brix
----

En esta sección de Predicción Brix se ha decidido entrenar distintos modelos de Machine Learning para poder seleccionar el que da mejores resultados con nuestros datos en la predicción del Brix.

**Regresión Lineal**
"""

# Inicializar el modelo para Brix
lin_reg = LinearRegression()

# Ajustar el modelo para Brix
lin_reg.fit(X_train, y_train)

# Realizar predicciones para Brix
y_pred_lin = lin_reg.predict(X_test)

# Evaluar el modelo para Brix
mse_lin = mean_squared_error(y_test, y_pred_lin)
r2_lin = r2_score(y_test, y_pred_lin)

print("Regresión Lineal para Brix")
print(f"Mean Squared Error: {mse_lin}")
print(f"R-squared: {r2_lin}\n")

"""**Árbol de Decisión**"""

# Inicializar el modelo
tree_reg = DecisionTreeRegressor()

# Ajustar el modelo
tree_reg.fit(X_train, y_train)

# Realizar predicciones
y_pred_tree = tree_reg.predict(X_test)

# Evaluar el modelo
mse_tree = mean_squared_error(y_test, y_pred_tree)
r2_tree = r2_score(y_test, y_pred_tree)

print("Árbol de Decisión")
print(f"Mean Squared Error: {mse_tree}")
print(f"R-squared: {r2_tree}\n")

"""**Random Forest**"""

# Inicializar el modelo
rf_reg = RandomForestRegressor()

# Ajustar el modelo
rf_reg.fit(X_train, y_train)

# Realizar predicciones
y_pred_rf = rf_reg.predict(X_test)

# Evaluar el modelo
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

print("Random Forest")
print(f"Mean Squared Error: {mse_rf}")
print(f"R-squared: {r2_rf}\n")

"""**Comparación Modelos Brix**"""

resultados = pd.DataFrame({
    'Modelo': ['Regresión Lineal', 'Árbol de Decisión', 'Random Forest'],
    'MSE': [mse_lin, mse_tree, mse_rf],
    'R-squared': [r2_lin, r2_tree, r2_rf]
})

print(resultados)

"""----
#Predicción pH
----

En esta sección de Predicción pH se ha decidido entrenar distintos modelos de Machine Learning para poder seleccionar el que da mejores resultados con nuestros datos en la predicción del pH, considerando que el valor de entrada a entrenar es el Brix de la matriz_y debido a que es el de mayor relación tiene.
"""

# Reshape necesario para sklearn, dado que brix es una variable de una dimensión
y_brix = y_brix.reshape(-1, 1)

# Usar train_test_split para dividir los datos de Brix y pH
X_train_brix, X_test_brix, y_train_ph, y_test_ph = train_test_split(y_brix, y_ph, test_size=0.3, random_state=42)

# Verificar las dimensiones de los conjuntos
print(f"Conjunto de entrenamiento: {X_train_brix.shape}, {y_train_ph.shape}")
print(f"Conjunto de prueba: {X_test_brix.shape}, {y_test_ph.shape}")

"""**Regresión Lineal**"""

# Inicializar el modelo de regresión lineal
lin_reg_brix_ph = LinearRegression()

# Ajustar el modelo usando los datos de entrenamiento (Brix como entrada, pH como salida)
lin_reg_brix_ph.fit(X_train_brix, y_train_ph)

# Realizar predicciones para el conjunto de prueba
y_pred_ph = lin_reg_brix_ph.predict(X_test_brix)

# Evaluar el modelo para predecir pH
mse_ph_lin = mean_squared_error(y_test_ph, y_pred_ph)
r2_ph_lin = r2_score(y_test_ph, y_pred_ph)

print("Modelo de Regresión Lineal: Predicción de pH a partir de Brix")
print(f"Mean Squared Error: {mse_ph_lin}")
print(f"R-squared: {r2_ph_lin}\n")

"""**Árbol de Decisión**"""

# Inicializar el modelo de Árbol de Decisión
tree_reg_brix_ph = DecisionTreeRegressor(random_state=42)

# Ajustar el modelo usando los datos de entrenamiento (Brix como entrada, pH como salida)
tree_reg_brix_ph.fit(X_train_brix, y_train_ph)

# Realizar predicciones para el conjunto de prueba
y_pred_ph_tree = tree_reg_brix_ph.predict(X_test_brix)

# Evaluar el modelo para predecir pH
mse_ph_tree = mean_squared_error(y_test_ph, y_pred_ph_tree)
r2_ph_tree = r2_score(y_test_ph, y_pred_ph_tree)

print("Árbol de Decisión: Predicción de pH a partir de Brix")
print(f"Mean Squared Error: {mse_ph_tree}")
print(f"R-squared: {r2_ph_tree}\n")

"""**Random Forest**"""

# Inicializar el modelo de Random Forest
rf_reg_brix_ph = RandomForestRegressor(n_estimators=100, random_state=42)

# Ajustar el modelo usando los datos de entrenamiento (Brix como entrada, pH como salida)
rf_reg_brix_ph.fit(X_train_brix, y_train_ph)

# Realizar predicciones para el conjunto de prueba
y_pred_ph_rf = rf_reg_brix_ph.predict(X_test_brix)

# Evaluar el modelo para predecir pH
mse_ph_rf = mean_squared_error(y_test_ph, y_pred_ph_rf)
r2_ph_rf = r2_score(y_test_ph, y_pred_ph_rf)

print("Random Forest: Predicción de pH a partir de Brix")
print(f"Mean Squared Error: {mse_ph_rf}")
print(f"R-squared: {r2_ph_rf}\n")

"""**Comparación Modelos pH**"""

resultados = pd.DataFrame({
    'Modelo': ['Regresión Lineal', 'Árbol de Decisión', 'Random Forest'],
    'MSE': [mse_ph_lin, mse_ph_tree, mse_ph_rf],
    'R-squared': [r2_ph_lin, r2_ph_tree, r2_ph_rf]
})

print(resultados)

"""---
# Conclusiones
---

**Discusión final**

El presente proyecto de TFM explica cada parte del código para realizar una predicción de los valores del Brix y pH que explican el nivel de calidad de la uva en distintos tiempos de madurez, desde la observación, tratamiento, entrenamiento y comparaciones de distintos modelos de Machine Learning de los datos. Concluyendo con la selección de Modelos.

**BRIX**: La regresión lineal obtiene el menor MSE y mayor R-squared, debido a que el modelo se ajusta bien a los datos lineales capturando la relación entre las variables de los espectros y Brix de manera eficiente al 75%. Se observa con los resutlados que los datos de entrada tienen una relación lineal significativa con el Brix, lo que favorece el desempeño de la regresión lineal sobre modelos más complejos, como árboles de decisión o random forest, que pueden sobreactuar en conjuntos de datos relativamente pequeños y con relaciones más simples.

**PH**: Usando Brix como variable de entrada, la regresión lineal también muestra el mejor desempeño aún siendo solo el 36% siendo considerado no muy bueno, lo que indica que existe una correlación lineal directa relativamente débil entre Brix y pH.

**Tabla Resumen**

| Predicción | Modelo | Variables | MSE | R-squared | Descripción|
| --- | --- | ------ | --- | --- |------ |
| Brix | Regresión Lineal | Horas, Tipo de Fermentación y Espectros | 1.607 | 0.7524 | La Regresión Lineal ajusta mejor todos los datos de las distintas variables con el error más bajo y predicción más alta.
| pH | Regresión Lineal | Brix | 0.012  | 0.3676 | La Regresión Lineal ajusta mejor a los datos del Brix con el error más bajo y predicción más alta.
|

**Recomendaciones:**

*   Para el tratamiento de datos con espectroscopía en gran cantidad de datos se recomienda usar el preparación de datos PCA para reducir en 2 o 3 componentes que expliquen la gran cantidad de variabilidad de los datos y así tener un manejo más accesible y rápido de análisis.

*   Se recomienda la captura de más variables para poder predecir con mayor porcentaje las variables Brix y Ph, ya que estás se ven afectadas por muchos otras variables.

*   Las variable tipo de fermentación especificamente en la ubicación de la uva en el racimo de uva guarda una relación relativamente débil con el Ph considerándose oportuna para futuros análisis del Ph.

*   La aplicación de Redes Neuronales puede ser una alternativa también para la predicción del Brix y Ph si consideramos más cantidad de muestras, debido a que en este trabajo se tienen pocas de cada tipo de fermentación reduciendo así su eficacia de este modelo que es bueno para robustos y complejos datos.
"""